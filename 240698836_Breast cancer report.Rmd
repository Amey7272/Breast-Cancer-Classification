---
title: "Breast Cancer Analysis"
author: "Amey Hari Madane"
output:
  html_document:
    df_print: paged
  pdf_document: default
header-includes:
   - \usepackage{setspace}
   - \renewcommand{\rmdefault}{phv}  # Set Helvetica for serif font
   - \renewcommand{\sfdefault}{phv}  # Set Helvetica for sans-serif font
   - \usepackage[scaled=0.92]{helvet}  # Adjust Helvetica font size as Arial is not available on this Latex Engine
fontsize: 11pt
    
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
## 1. Abstract

The dataset is collected from 699 breast cancer biopsies performed at the University of Wisconsin, using fine needle aspiration cytology. It examines nine different characteristics in a scale of one through ten for cell size and shape, which dictates the healthiness of the cells. The key objective is to see if these variables alone can correctly classify the tissue sample as benign or malignant. Assuming these women are a random subset showing symptoms of breast cancer, the project will try to study this dataset in detail. It will involve the fitting of a logistic regression model by best subset selection and the implementation of the Lasso penalty method. In addition, Linear Discriminant Analysis will be employed. The idea is to assess the dependability of these features in separating benign from malignant tissue of the breast. A successful outcome could significantly impact breast cancer diagnosis, aiding in more informed treatment decisions.

## 2. Data Exploration
First of all, the exploration and preparation of data was done by changing the variables from factors to numerical representations. Then class variables were changed into numerical where 'benign' was represented as 0 and 'malignant' as 1. Interestingly, there were 16 missing attributes in the 'Bare.Nuclei' column. In order to handle it, the rows with missing attributes were deleted. This resulted in the dataset being left with 444 observations for benign and 239 observations as malignant.

```{r, message = FALSE, warning = FALSE}
library(dplyr)
## Load mlbench package
library(mlbench)
# Required libraries
library(caret)
library(purrr)
library(bestglm)
## Load the glmnet package
library(glmnet)
library(MASS)
library(tidyverse)
library(ggplot2)

```


```{r}
## Load the data
data(BreastCancer)
```

```{r}
#transform features from factor to integer
BreastCancer = BreastCancer %>%
  mutate(across(1:10, as.character)) %>%
  mutate(across(1:10, as.numeric))
#Transform class variable into 0 and 1's
BreastCancer$Class = as.integer(BreastCancer$Class) - 1
```

```{r}
#Removing Null values
BreastCancer = BreastCancer %>%
  filter(!is.na(Bare.nuclei))
```
### 2.1  Data Summary
```{r}
summary(BreastCancer[ , 2:10])
```

The summary gives an overview of the range, dispersion, and central tendencies of each predictor variable, hence giving a good view of how each varies within the data. Features such as 'Cl.thickness' have higher means with larger ranges, which may indicate large variability in the dataset. Mitoses has the lowest mean and variability across the dataset.

### 2.2 Facet Grid Scatterplot 
```{r}
# Convert the dataset into a long format
data_long <- BreastCancer %>%
  gather(key = "Variable", value = "Value", 2:10) %>%
  mutate(Class = as.factor(Class))

# Facet grid scatterplots
ggplot(data_long, aes(x = Value, y = Variable, color = Class)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~Variable, scales = "free") +
  theme_minimal()
```

The scatterplot matrix shows that the clear separation between the two classes in response variables proves there is a clear distinction. However, weaker separations were found within normal.nucleoli, bare.nuclei, marg.adhesion, and epith.c.size; this indicates that class values in these particular variables are overlapped. Most importantly, cell.size and cell.shape can be said to hold a very strong positive relationship; thus, as one variable increases, so does the other. These findings give valuable insight into the class separations and interrelationships among the predictor variables in this dataset.

### 2.3 Covariance matrix
```{r}
cov_matrix = var(BreastCancer[,2:10])
cov_matrix
```

The covariance matrix shows the interaction between the predictor variables in the data. From the matrix, one can observe that the covariances between 'Cell.size', 'Cell.shape', and 'Bare.nuclei' are much higher, indicating that there is a greater positive relationship within these features. In other words, if one of these three variables increases, then the others will grow accordingly; thus, there could be some multicollinearity between them. Whereas very low covariance values, such as between 'Cl.thickness', 'Marg.adhesion', 'Epith.c.size', and other variables, are indicative of weaker associations or less linear dependence within these specific features. Finally, Mitoses has a weak positive relationship with all the variables. The elements on the diagonal of the matrix represent the variance of the variables, therefore showing the spread/variability of each predictor variable individually.

### 2.4 Correlation matrix
```{r}
cor(BreastCancer[,2:11])
```

  **Correlation Between Response and Predictor Variables:**

The 'Class' variable correlates strongly positively with all the predictor variables: 'Cl.thickness', 'Cell.size', 'Cell.shape', 'Marg.adhesion', 'Epith.c.size', 'Bare.nuclei', and 'Bl.cromatin', whose magnitude falls between 0.71 to 0.82. This means that as these variables increase, there is a tendency to associate more with the 'Class' variable, which may indicate that these features are important to predict benign or malignant status.The 'Mitoses' variable has a weaker correlation of 0.42 with the 'Class' variable than other predictors, suggesting it has a relatively less strong relationship in predicting the class.

```{r}
# Exclude the first column ('ID') from the dataset
BreastCancer <-  BreastCancer[, names(BreastCancer) != "Id"]
```

```{r}
# Set the seed for reproducibility
set.seed(123)
# Split the dataset into 80% training and 20% testing
trainIndex = createDataPartition(BreastCancer$Class, p = 0.8, list = FALSE)
training = BreastCancer[trainIndex, ]
testing = BreastCancer[-trainIndex, ]

# Separate predictors (X) and target variable (y) in both train and test sets
X_train = training[, -which(names(training) == "Class")]
y_train = training$Class

X_test = testing[, -which(names(testing) == "Class")]
y_test = testing$Class
```

## 3. Fitting a logistic regression model.
.

```{r}
#Standardise X_train and x_test
X_train = scale(X_train)
center = attr(X_train, "scaled:center")
scale = attr(X_train, "scaled:scale")
X_test = scale(X_test, center=center, scale=scale)
#Create test and train dataframe
CancerTrain_data = data.frame(X_train, y_train)
CancerTest_data = data.frame(X_test, y_test)
#store values for n and p
n = nrow(CancerTrain_data); p = ncol(CancerTrain_data) - 1
```

```{r}
#fit a logistic regression model
logreg_fit = glm(y_train ~ ., data=CancerTrain_data, family="binomial")
summary(logreg_fit)
```

The maximum likelihood estimates of the regression coefficients are therefore

$\hat{\beta}_0 = -1.002, \hat{\beta}_1 = 1.095, \hat{\beta}_2 = 0.503, \hat{\beta}_3 = 0.817, \hat{\beta}_4 = 0.919, \hat{\beta}_5 = 0.092, \hat{\beta}_6 = 1.515, \hat{\beta}_7 = 1.390, \hat{\beta}_8 = 0.456, \hat{\beta}_9 = 0.890$

The p-value for Cl.thickness, Marg.adhesion, Bare.nuclei and Bl.cromatin is less than 0.05
If we look at the table produced by the summary function we see that a number of the variables have very large p-values meaning that, individually, they contribute very little to a model which contains all the other predictors.Inclusion of more predictors than are necessary can inflate the variance of the parameter estimators leading to a deterioration in predictive performance.

## 4. Best Subset Selection in logistic regression

In the earlier model it is observed that some of the features do not have any significant effect on the model's output. Therefore to find the optimal model we apply different feature selection techniques.   
We can apply best subset selection using BIC using the bestglm package.

```{r, message=FALSE}
set.seed(123)
bss_fit_BIC = bestglm(CancerTrain_data, family=binomial, IC="BIC")
best_BIC = bss_fit_BIC$ModelReport$Bestk
```


 **BIC Subsets**
```{r}
bss_fit_BIC$Subsets
```
 
BIC: Penalizes complexity more than AIC and often selects smaller models compared to AIC. .  
Here BIC has selected best model with 5 predictors to be the best.  


### 4.1 Best subset selection with BIC
```{r}
pstar = 5
## Construct a reduced data set containing only the selected predictors
indices = as.logical(bss_fit_BIC$Subsets[pstar+1, 2:(p+1)])

Cancer_data_red_BIC = data.frame(X_train[,indices], y_train)
Cancer_data_red_BIC_test =  data.frame(X_test[,indices], y_test)
```

```{r}
## Obtain logistic regression coefficients for BIC model
logreg1_fit = glm(y_train ~ ., data=Cancer_data_red_BIC, family = "binomial")
summary(logreg1_fit)
```
The maximum likelihood estimates of the regression coefficients are

$\hat{\beta}_0 = -1.05, \hat{\beta}_1 = 1.433, \hat{\beta}_2 = 1.539, \hat{\beta}_3 = 1.008, \hat{\beta}_4 = 1.631, \hat{\beta}_5 = 1.480$    

The model summary clearly indicates a robust association between the predictor and response variables. Each variable exhibits positive coefficients, signifying a positive relationship. Additionally, all variables demonstrate p-values below 0.05, indicating a strong statistical significance and reinforcing the presence of a compelling positive correlation among the variables.

This model has selected Cl.thickness, Cell.size, Marg.adhesion, Bare.nuclei and Bl.cromatin variables and rest all are dropped from the model. These variables showed strong positive correlation with Class variable in the earlier correlation matrix. 4 of the variables except Cell.size had p-values less than 0.05 in earlier simple logistic regression model.

### 4.2 Test error

```{r}
#calculating test error of BIC
## Compute predicted probabilities:
phat_test = predict(logreg1_fit, data.frame(Cancer_data_red_BIC_test), type = "response")
## Compute fitted (i.e. predicted) values:
yhat = ifelse(phat_test > 0.5, 1, 0)
print("Confusion matrix of subset selection with BIC")
## Calculate confusion matrix:
(confusion = table(Observed = y_test, Predicted = yhat))
```

```{r}
## Calculate the test error:
print("Test error for best subset selection with BIC is: ")
1 - mean(y_test == yhat)
```
The test error for best subset selection with BIC is 3.67%. This error is less compared to the first regression model.

```{r}
plot(0:p, bss_fit_BIC$Subsets$BIC, 
     xlab = "Number of predictors", 
     ylab = "BIC", 
     type = "b", 
     cex = 0.7)  # Reduce point size
points(best_BIC, bss_fit_BIC$Subsets$BIC[best_BIC + 1], col = "red", pch = 16, cex = 1.0)
```

## 5. Regularized Logistic regression with Lasso penalty
```{r}
## Choose grid of values for the tuning parameter
grid = 10^seq(-3,-0.3, length.out=100)
## Fit a model with LASSO penalty for each value of the tuning parameter
lasso_fit = glmnet(X_train, y_train, family="binomial", 
                   alpha = 1, standardize = FALSE, lambda=grid)
```


```{r, out.width = "85%"}
lasso_cv_fit = cv.glmnet(as.matrix(X_train), y_train, family = "binomial", 
                         alpha = 1, standardize = FALSE, lambda = grid, type.measure = "class")
#plot(lasso_cv_fit)
```

```{r}
## Identify the optimal value for the tuning parameter
lambda_lasso_min = lasso_cv_fit$lambda.min
which_lambda_lasso = which(lasso_cv_fit$lambda == lambda_lasso_min)
## Find the parameter estimates associated with optimal value of the tuning parameter
coef(lasso_fit, s=lambda_lasso_min)
```
At the optimal solution none of the variables drop out of the model

### 5.1 Test error
```{r}
#Calculating test error of Lasso
## Compute predicted probabilities:
phat_test = predict(lasso_fit, X_test, s = lambda_lasso_min, type="response")
## Compute fitted (i.e. predicted) values:
yhat_test = ifelse(phat_test > 0.5, 1, 0)
## Calculate confusion matrix:
(confusion = table(Observed = y_test, Predicted = yhat_test))
```

```{r}
## Calculate the test error:
print("Test error for logistic regression with Lasso is: ")
1 - mean(y_test == yhat_test)
```
The test error (5.1%) is slightly higher for the model fitted with the LASSO penalty. Therefore of the two models, it seems that the model fitted without penalty performs better, based on this particular partition of the data into training and validation sets.

## 6. Bayes classifier for Linear Disciminant Analysis

All the variables have been used in the LDA model.
```{r}
lda_model = lda(y_train ~ ., data = data.frame(X_train))
lda_model
```
Above model shows, Prior probabilities of groups:   
64.89% belongs to benign cancer and 35.10% belongs to malignant cancer.  
Group means   
It shows the class wise average (standardised) values for each predictor variables. This helps in comparing how the average values of variables varies between two class. A large difference in average values suggests good seperation between the classes.   

### 6.1 Test error
```{r}
#Calculating test error of LDA
## Compute predicted probabilities:
phat_test = predict(lda_model, data.frame(CancerTest_data), type = "response")
## Compute fitted (i.e. predicted) values:
yhat_test = phat_test$class
## Calculate confusion matrix:
(confusion = table(Observed = y_test, Predicted = yhat_test))
```

```{r}
## Calculate the test error:
print("Test error for logistic regression with LDA is: ")
1 - mean(y_test == yhat_test)
```
The test error for the linear discriminant analysis model is 6.6% which is highest among all the methods implemented on the Breast Cancer dataset.

# 7. Conclusion

Among these five variants of logistic regression for the Breast Cancer data set to predict the type of cancer, namely benign or malignant, the model using best subset selection method using BIC had turned out to be the best. This model showed an error rate of 3.6%, reflecting its accuracy of prediction.

This selected logistic regression model comprises five predictor variables: Cl.thickness, Cell.size, Marg.adhesion, Bare.nuclei, and Bl.cromatin. These variables showcase a notably strong positive correlation with the target class variable. Moreover, they exhibit statistical significance with p-values less than 0.05, further affirming their relevance in the prediction process

Including more than five variables in the logistic regression model-in particular, utilizing all variables in methods like Lasso or LDA-results in higher errors. This indicates that the extra variables outside of the best subset or the full set of variables are not adding much value to enhancing the predictive power of the model.

These additional variables add nothing valuable to the model in terms of predicting type, whether it be benign or malignant. Because of this, their inclusion tends to cause noise and irrelevant information, leading to an increase in error rates without corresponding improvement in predictive accuracy. The best performance of the model is, therefore, achieved in considering a limited set of five predictor variables that are strongly associated with the target class variable, while statistical significance and error rate are low.